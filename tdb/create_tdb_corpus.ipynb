{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ライブラリの読み込み\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot  as plt\n",
    "import itertools\n",
    "import time\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import MeCab\n",
    "from numpy.random import *\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 250)\n",
    "pd.set_option(\"display.max_columns\", 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cabochaの結果をクレンジング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ファイルの読み込み\n",
    "nlp_path = \"D:/Statistics/data/NLP/\"\n",
    "tdb = pd.read_csv(nlp_path + \"tdb/tdb_result_by_sentence.csv\", dtype=\"str\")\n",
    "tdb[\"d_id\"] = tdb[\"d_id\"].astype(\"int\")\n",
    "tdb[\"no\"] = tdb[\"no\"].astype(\"int\")\n",
    "\n",
    "f = open(nlp_path + \"tdb/cabocha_text_neologd.txt\",encoding=\"utf-8\")\n",
    "cabocha_text = f.readlines()  # ファイル終端まで全て読んだデータを返す\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 改行を変換\n",
    "n = len(cabocha_text)\n",
    "for i in range(n):\n",
    "    cabocha_text[i] = re.sub(\"\\n\", \"\", cabocha_text[i])\n",
    "    cabocha_text[i] = re.sub(\"\\t\", \" \", cabocha_text[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 係り受け結果を抽出\n",
    "# データの格納用配列\n",
    "get_id = 0\n",
    "id_list = []\n",
    "res_morpheme = []\n",
    "res_dependency = []\n",
    "\n",
    "# 1文ずつデータを処理\n",
    "for i in range(n):\n",
    "    if i%100000==0:\n",
    "        print(i)\n",
    "    flag = len(re.findall(\"\\* [0-9]\", cabocha_text[i][:3])) > 0\n",
    "    if flag==True:\n",
    "        dependency = cabocha_text[i]\n",
    "    else:\n",
    "        split_result = re.split(\"[ , \\,]\", cabocha_text[i])\n",
    "        if len(split_result)==8:\n",
    "            split_result.extend(np.repeat(split_result[0], 2).tolist())\n",
    "        if len(split_result)==10:\n",
    "            id_list.append(np.array(tdb[\"d_id\"].iloc[get_id]))\n",
    "            res_dependency.append(re.split(\" \", dependency))\n",
    "            res_morpheme.append(split_result)\n",
    "    if cabocha_text[i]==\"EOS\":\n",
    "        get_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データフレームを作成\n",
    "# データフレームに変換\n",
    "d_id = pd.DataFrame({\"d_id\": np.array(id_list)})\n",
    "dependency = pd.DataFrame(np.array(res_dependency)).iloc[:, 1:]\n",
    "morpheme = pd.DataFrame(np.array(res_morpheme)).iloc[:, :8]\n",
    "dependency.columns = [\"send_id\", \"receive_id\", \"head\", \"score\"]\n",
    "morpheme.columns = [\"word\", \"class\", \"class_detail1\", \"class_detail2\", \"class_detail3\", \"inflection1\", \"inflection2\", \"genkei\"]\n",
    "dependency_df = pd.concat((d_id, dependency, morpheme), axis=1)\n",
    "dependency_df = dependency_df.iloc[np.where(dependency_df[\"word\"]!=\"\")[0]]\n",
    "dependency_df.index = np.arange(dependency_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データフレームのデータ型を変更\n",
    "n = dependency_df.shape[0]\n",
    "receive_id = np.array(dependency_df[\"receive_id\"])\n",
    "dependency_df[\"receive_id\"] = np.array([re.sub(\"D\", \"\", receive_id[i]) for i in range(n)], dtype=\"int\")\n",
    "dependency_df[\"send_id\"] = np.array(dependency_df[\"send_id\"], dtype=\"int\")\n",
    "dependency_df[\"score\"] = np.array(dependency_df[\"score\"], dtype=\"float\")\n",
    "\n",
    "# 新しいphrase idを定義\n",
    "joint_id = np.array(dependency_df[\"d_id\"].astype(\"str\") + \"-\" + dependency_df[\"send_id\"].astype(\"str\"))\n",
    "phrase_mapping = pd.DataFrame({\"joint_id\": pd.unique(joint_id), \"phrase_id\": np.arange(len(pd.unique(joint_id)))})\n",
    "phrase_id = pd.merge(pd.DataFrame({\"joint_id\": joint_id}), phrase_mapping, on=\"joint_id\", how=\"inner\")\n",
    "dependency_df[\"phrase_id\"] = phrase_id[\"phrase_id\"]\n",
    "\n",
    "# 補助情報を統合\n",
    "result = pd.merge(dependency_df, tdb[[\"kgcd\", \"d_id\", \"no\"]], on=\"d_id\", how=\"inner\")\n",
    "result[\"serial_no\"] = np.arange(result.shape[0])\n",
    "result = result[[\"serial_no\", \"kgcd\", \"d_id\", \"no\", \"phrase_id\", \"send_id\", \"receive_id\", \"head\", \"score\", \"word\", \"genkei\",\n",
    "                 \"class\", \"class_detail1\", \"class_detail2\", \"class_detail3\", \"inflection1\", \"inflection2\"]]\n",
    "\n",
    "# 「及び」を「および」に修正\n",
    "index = np.where((result[\"word\"]==\"及び\") & (result[\"class\"]==\"接続詞\"))[0].astype(\"int\")\n",
    "result[\"word\"].iloc[index] = \"および\"\n",
    "result[\"genkei\"].iloc[index] = \"および\"\n",
    "del res_dependency, res_morpheme, id_list, dependency, morpheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データフレームを出力\n",
    "result.to_csv(nlp_path + \"tdb/tdb_corpus.csv\", index=None)\n",
    "\n",
    "split = 3\n",
    "kgcd = np.unique(result[\"kgcd\"])\n",
    "split_kgcd = np.array_split(kgcd, split, 0)\n",
    "for j in range(split):\n",
    "    index = np.where(np.in1d(result[\"kgcd\"], split_kgcd[j]))[0]\n",
    "    result_split = result.iloc[index]\n",
    "    result_split.to_excel(nlp_path + \"tdb/tdb_corpus\" + str(j) + \".xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.unique(result[\"phrase_id\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(result[\"phrase_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
